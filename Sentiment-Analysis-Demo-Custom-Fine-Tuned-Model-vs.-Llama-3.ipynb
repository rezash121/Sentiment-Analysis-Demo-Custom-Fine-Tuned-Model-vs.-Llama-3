{"cells":[{"cell_type":"markdown","source":["**Vide link:**\n","\n","https://youtu.be/Y_wiJANVcL0\n","\n","**Github link:**\n","\n","https://github.com/rezash121/Sentiment-Analysis-Demo-Custom-Fine-Tuned-Model-vs.-Llama-3\n"],"metadata":{"id":"hqGstd5EoS8v"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3839,"status":"ok","timestamp":1738663752911,"user":{"displayName":"Reza Shafiloo","userId":"13455316872907877314"},"user_tz":-120},"id":"Qs6kALUWRwhZ","outputId":"6c2eb094-c613-4751-fb28-bbdecde4149d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Path to dataset files: /root/.cache/kagglehub/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews/versions/1\n","Files in the dataset directory: ['IMDB Dataset.csv']\n","\n","First five rows of the dataset:\n","                                              review sentiment\n","0  One of the other reviewers has mentioned that ...  positive\n","1  A wonderful little production. <br /><br />The...  positive\n","2  I thought this was a wonderful way to spend ti...  positive\n","3  Basically there's a family where a little boy ...  negative\n","4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n","\n","Dataset information:\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 50000 entries, 0 to 49999\n","Data columns (total 2 columns):\n"," #   Column     Non-Null Count  Dtype \n","---  ------     --------------  ----- \n"," 0   review     50000 non-null  object\n"," 1   sentiment  50000 non-null  object\n","dtypes: object(2)\n","memory usage: 781.4+ KB\n","None\n"]}],"source":["# Import the necessary libraries\n","import pandas as pd\n","import kagglehub\n","import os\n","\n","# Download the latest version of the dataset from Kaggle\n","dataset_dir = kagglehub.dataset_download(\"lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\")\n","print(\"Path to dataset files:\", dataset_dir)\n","\n","# List the files in the downloaded directory to find the CSV file\n","files = os.listdir(dataset_dir)\n","print(\"Files in the dataset directory:\", files)\n","\n","csv_file = os.path.join(dataset_dir, \"IMDB Dataset.csv\")\n","\n","# Load the dataset using Pandas\n","df = pd.read_csv(csv_file)\n","\n","# Verify the dataset by printing the first few rows and its info\n","print(\"\\nFirst five rows of the dataset:\")\n","print(df.head())\n","\n","print(\"\\nDataset information:\")\n","print(df.info())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1827,"status":"ok","timestamp":1738663754734,"user":{"displayName":"Reza Shafiloo","userId":"13455316872907877314"},"user_tz":-120},"id":"jQCOLCnlR7Gs","outputId":"46b0221f-ab1a-4996-c59b-28a84692371a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset after preprocessing (first five rows):\n","                                              review  label\n","0  One of the other reviewers has mentioned that ...      1\n","1  A wonderful little production. <br /><br />The...      1\n","2  I thought this was a wonderful way to spend ti...      1\n","3  Basically there's a family where a little boy ...      0\n","4  Petter Mattei's \"Love in the Time of Money\" is...      1\n","\n","Dataset info:\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 50000 entries, 0 to 49999\n","Data columns (total 2 columns):\n"," #   Column  Non-Null Count  Dtype \n","---  ------  --------------  ----- \n"," 0   review  50000 non-null  object\n"," 1   label   50000 non-null  int64 \n","dtypes: int64(1), object(1)\n","memory usage: 781.4+ KB\n","None\n","\n","Dataset split sizes:\n","Training set: (36000, 2)\n","Validation set: (4000, 2)\n","Testing set: (10000, 2)\n"]}],"source":["from sklearn.model_selection import train_test_split\n","\n","\n","# Step 1: Encode the sentiment column: positive -> 1, negative -> 0.\n","df['label'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n","\n","# Step 2: Retain only the review and label columns.\n","df = df[['review', 'label']]\n","\n","# Verify changes: print first few rows and info\n","print(\"Dataset after preprocessing (first five rows):\")\n","print(df.head())\n","print(\"\\nDataset info:\")\n","print(df.info())\n","\n","# Step 3: Split the data into training, validation, and testing sets.\n","\n","train_val_df, test_df = train_test_split(df, test_size=0.20, random_state=42, stratify=df['label'])\n","\n","train_df, val_df = train_test_split(train_val_df, test_size=0.10, random_state=42, stratify=train_val_df['label'])\n","\n","# Print the sizes of the splits\n","print(\"\\nDataset split sizes:\")\n","print(\"Training set:\", train_df.shape)\n","print(\"Validation set:\", val_df.shape)\n","print(\"Testing set:\", test_df.shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":59393,"status":"ok","timestamp":1738663818577,"user":{"displayName":"Reza Shafiloo","userId":"13455316872907877314"},"user_tz":-120},"id":"FvUAHNdEVhuH","outputId":"8a0a4710-91fb-42db-a406-8474fada9afe"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Sample tokenized output (from Training set):\n","{'input_ids': [101, 1996, 3185, 4627, 2125, 2004, 2057, 2156, 1037, 8333, 1997, 1037, 4121, 14734, 2067, 1999, 1996, 2382, 1005, 1055, 1999, 2637, 1012, 2059, 1037, 2460, 2466, 2003, 3491, 2055, 1037, 17109, 1011, 2559, 7500, 12005, 3900, 2040, 2081, 1037, 3066, 2007, 16795, 1010, 2000, 2131, 2204, 11203, 1012, 12005, 3900, 5086, 2402, 2273, 2000, 2147, 1999, 2010, 3871, 1010, 2730, 2068, 1010, 1998, 2109, 2004, 12665, 24375, 2015, 1012, 2002, 2036, 7349, 1996, 2598, 2007, 2037, 2668, 1012, 2070, 2051, 2044, 1016, 10558, 2272, 2000, 3942, 2032, 1012, 2028, 1997, 2068, 4152, 2915, 2011, 12005, 3900, 1010, 2178, 2028, 8563, 1996, 7500, 2370, 1012, 1012, 1012, 2044, 2008, 1010, 1996, 2556, 2154, 2003, 3491, 1010, 1998, 2070, 3124, 2315, 5977, 2003, 2409, 2008, 2002, 2038, 2019, 2214, 3888, 2187, 2004, 12839, 1012, 2002, 7288, 2000, 2175, 2045, 2007, 2070, 2814, 2000, 2156, 2054, 1005, 1055, 2039, 1012, 2210, 2106, 5977, 2113, 2008, 1996, 2279, 2305, 2003, 1996, 1000, 3477, 5963, 2305, 1000, 1012, 1012, 1012, 1012, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2004, 2005, 2033, 2023, 3185, 2018, 1037, 2204, 2466, 2005, 1037, 5469, 17312, 1010, 2021, 2659, 5166, 1998, 3532, 2569, 3896, 2074, 9868, 2009, 1012, 1000, 2601, 11203, 1000, 2003, 1037, 3819, 2742, 1997, 13971, 2143, 2437, 1012, 2005, 2742, 2057, 2156, 1037, 12665, 24375, 1006, 1037, 5156, 3124, 4147, 1037, 6057, 1010, 10036, 7308, 1007, 11777, 1037, 2611, 1012, 2043, 2002, 13275, 2010, 2192, 2057, 2131, 2000, 2156, 1037, 3671, 2529, 3096, 2917, 2010, 15913, 1010, 2612, 1997, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"]}],"source":["from transformers import AutoTokenizer\n","\n","# Step 1: Select the pre-trained Hugging Face transformer model for fine-tuning.\n","model_name = \"distilbert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","# Step 2: Define tokenization parameters:\n","tokenization_params = dict(truncation=True, padding='max_length', max_length=256)\n","\n","# Tokenize the datasets:\n","# Convert the 'review' column from each pandas DataFrame into a list and tokenize.\n","train_encodings = tokenizer(train_df['review'].tolist(), **tokenization_params)\n","val_encodings = tokenizer(val_df['review'].tolist(), **tokenization_params)\n","test_encodings = tokenizer(test_df['review'].tolist(), **tokenization_params)\n","\n","# Display a sample tokenized output from the training set.\n","print(\"Sample tokenized output (from Training set):\")\n","sample_tokens = {key: train_encodings[key][0] for key in train_encodings}\n","print(sample_tokens)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":557,"referenced_widgets":["a2b75a5ea86d499ea1f01d677df5e0d5","cbe9d213797542ebac54b9d27fb6032d","cdde8509e17d4f808dd6c4349641dcf9","4d4674fb51904c1983e508d8bca6df5c","e3e3929047034234b35aa11052b44798","394d58d2d7de463c8b155e85b8be16b6","e08dbc39a361471e9e3ba789c7ca7fc5","bf8d2cb4b8764084912cca9f1afa06fd","dcdd3b9eaf8b4de2ac672806cffbfbd6","1cac4692477e4d88b8cab17ef1f7d950","b2f067a0a3674fbaa19b6b4f5d5fd0cf"]},"id":"j7wbfJkDWSJH","executionInfo":{"status":"ok","timestamp":1738665628989,"user_tz":-120,"elapsed":1800431,"user":{"displayName":"Reza Shafiloo","userId":"13455316872907877314"}},"outputId":"c258ce24-c23a-4710-e3d9-90fdbdd7a066"},"outputs":[{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2b75a5ea86d499ea1f01d677df5e0d5"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":[" ··········\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrza121\u001b[0m (\u001b[33mrzash121\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.5"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250204_101102-b8edzu7e</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/rzash121/huggingface/runs/b8edzu7e' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/rzash121/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/rzash121/huggingface' target=\"_blank\">https://wandb.ai/rzash121/huggingface</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/rzash121/huggingface/runs/b8edzu7e' target=\"_blank\">https://wandb.ai/rzash121/huggingface/runs/b8edzu7e</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='4500' max='4500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4500/4500 28:53, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.282900</td>\n","      <td>0.208570</td>\n","      <td>0.918000</td>\n","      <td>0.920523</td>\n","      <td>0.915000</td>\n","      <td>0.917753</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.138600</td>\n","      <td>0.268623</td>\n","      <td>0.920750</td>\n","      <td>0.912702</td>\n","      <td>0.930500</td>\n","      <td>0.921515</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [250/250 00:29]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Evaluation results: {'eval_loss': 0.2686232924461365, 'eval_accuracy': 0.92075, 'eval_precision': 0.9127023050514959, 'eval_recall': 0.9305, 'eval_f1': 0.9215152265412231, 'eval_runtime': 29.5001, 'eval_samples_per_second': 135.593, 'eval_steps_per_second': 8.475, 'epoch': 2.0}\n"]}],"source":["import torch\n","import numpy as np\n","from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","\n","# Step 1: Load the pre-trained model for sequence classification.\n","model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n","\n","# Step 2: Define a custom dataset class to work with the Trainer.\n","class IMDbDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item[\"labels\"] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","# Create dataset instances for training, validation, and testing.\n","train_dataset = IMDbDataset(train_encodings, train_df[\"label\"].tolist())\n","val_dataset   = IMDbDataset(val_encodings, val_df[\"label\"].tolist())\n","test_dataset  = IMDbDataset(test_encodings, test_df[\"label\"].tolist())\n","\n","# Step 3: Define the metric computation function.\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    preds = np.argmax(logits, axis=1)\n","    accuracy = accuracy_score(labels, preds)\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n","    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n","\n","# Step 4: Set up training arguments.\n","training_args = TrainingArguments(\n","    output_dir=\"./results\",            # Output directory for model predictions and checkpoints.\n","    num_train_epochs=2,                # Total number of training epochs.\n","    per_device_train_batch_size=16,    # Batch size for training (adjust to 16 or 32 as desired).\n","    per_device_eval_batch_size=16,     # Batch size for evaluation.\n","    evaluation_strategy=\"epoch\",       # Evaluation is done at the end of each epoch.\n","    learning_rate=5e-5,                # Learning rate.\n","    logging_strategy=\"epoch\",          # Log metrics at the end of each epoch.\n","    save_strategy=\"epoch\",             # Save checkpoints at the end of each epoch.\n","    load_best_model_at_end=True,       # Load the best model when finished training.\n","    metric_for_best_model=\"f1\",        # Use F1 score to evaluate the best model.\n","    logging_dir='./logs',              # Directory for storing logs.\n",")\n","\n","# Step 5: Instantiate the Trainer.\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    compute_metrics=compute_metrics,\n",")\n","\n","# Step 6: Fine-tune the model.\n","trainer.train()\n","\n","# Optional: Evaluate the model on the validation set.\n","eval_results = trainer.evaluate()\n","print(\"Evaluation results:\", eval_results)\n"]},{"source":["# Save the fine-tuned model and tokenizer locally.\n","model_save_path = \"./imdb-finetuned-model\"\n","model.save_pretrained(model_save_path)\n","tokenizer.save_pretrained(model_save_path)\n","print(f\"Model and tokenizer saved locally at {model_save_path}\")\n","\n","# Log in to the Hugging Face Hub.\n","from huggingface_hub import login # Import login function\n","\n","login(token=\"##############\") # Use login function with token argument\n","\n","\n","# Upload (push) the model and tokenizer to the Hugging Face Hub.\n","repo_name = \"rza121/imdb-finetuned-model\"\n","model.push_to_hub(repo_name)\n","tokenizer.push_to_hub(repo_name)"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["ec31ab034b6341f09f90e2d0b6b5ffa1","f8dddccdf18446f78d2192dcd27c0bdf","3c9e966b05324c28995fc4dd031c0fb5","78cb9eac7ab04e7dafe945c9408edf6d","6f847ffb05cb4173abe5f6a4eae5abe3","41d0b4373d984579a3f684ae5c874d5a","2551d6af41514cadaf046608b47880c4","c9dc1e43ddc14b71a9e78cec3c1a63f0","55527ec61dfd42c9b014920efde60796","c31aaa1b7107409e8e83b7963a30515c","30c2793f21684e2d9121e1607f8d5401"]},"id":"rWc5nE9bnm_5","executionInfo":{"status":"ok","timestamp":1738667046917,"user_tz":-120,"elapsed":26796,"user":{"displayName":"Reza Shafiloo","userId":"13455316872907877314"}},"outputId":"4a4cb366-c51f-44e6-d516-f4de0a64fad1"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec31ab034b6341f09f90e2d0b6b5ffa1"}},"metadata":{}}]},{"cell_type":"code","source":["!pip install fastapi uvicorn pyngrok\n"],"metadata":{"id":"YiUfxD5bjbys"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!killall uvicorn || echo \"No uvicorn process found\""],"metadata":{"id":"jiQ9tFcN7Ngm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import required modules\n","from fastapi import FastAPI, HTTPException\n","from pydantic import BaseModel\n","import nest_asyncio\n","import uvicorn\n","from pyngrok import ngrok\n","import threading\n","\n","# Apply nest_asyncio to allow nested event loops (required for Colab)\n","nest_asyncio.apply()\n","\n","# Kill existing ngrok tunnels to avoid exceeding the limit\n","ngrok.kill()\n","\n","# Optionally kill any server processes using port 8003 (uncomment if necessary)\n","!fuser -k 8003/tcp\n","\n","# Set your ngrok authtoken (replace with your actual authtoken)\n","ngrok.set_auth_token(\"##############\")\n","\n","# Step 2: Define the FastAPI app and endpoints\n","app = FastAPI()\n","\n","# Define the request body structure using Pydantic.\n","class AnalyzeRequest(BaseModel):\n","    text: str\n","    model: str\n","\n","# Define the response structure.\n","class AnalyzeResponse(BaseModel):\n","    sentiment: str\n","    confidence: float\n","\n","@app.post(\"/analyze/\", response_model=AnalyzeResponse)\n","async def analyze(request: AnalyzeRequest):\n","    # Check for empty text.\n","    if not request.text:\n","        raise HTTPException(status_code=400, detail=\"Input text cannot be empty.\")\n","\n","    # Dummy sentiment analysis logic.\n","    if request.model.lower() == \"custom\":\n","        if \"good\" in request.text.lower():\n","            sentiment = \"positive\"\n","            confidence = 0.95\n","        else:\n","            sentiment = \"negative\"\n","            confidence = 0.90\n","    elif request.model.lower() == \"llama\":\n","        if \"happy\" in request.text.lower():\n","            sentiment = \"positive\"\n","            confidence = 0.93\n","        else:\n","            sentiment = \"negative\"\n","            confidence = 0.88\n","    else:\n","        raise HTTPException(status_code=400, detail=\"Invalid model specified. Choose 'custom' or 'llama'.\")\n","\n","    return AnalyzeResponse(sentiment=sentiment, confidence=confidence)\n","\n","# Step 3: Run the FastAPI app using Uvicorn in a background thread\n","\n","# Define the port number (using 8003)\n","port = 8003\n","\n","# Start ngrok tunnel on port 8003\n","tunnel = ngrok.connect(port)\n","public_url = tunnel.public_url\n","print(\"ngrok tunnel created! Public URL:\", public_url)\n","\n","# Function to run the Uvicorn server\n","def run():\n","    uvicorn.run(app, host=\"0.0.0.0\", port=port)\n","\n","# Start the server in a new thread.\n","thread = threading.Thread(target=run)\n","thread.start()\n"],"metadata":{"id":"W4Kf9JB6pmOq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import requests\n","\n","# Build the endpoint URL\n","endpoint_url = public_url + \"/analyze/\"\n","print(\"Endpoint URL:\", endpoint_url)\n","\n","# Define the payload for the POST request.\n","payload = {\"text\": \"This movie was really good!\", \"model\": \"custom\"}\n","\n","# Send the POST request and print the JSON response.\n","response = requests.post(endpoint_url, json=payload)\n","print(\"Response:\", response.json())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z8AUPc1Vtcsl","executionInfo":{"status":"ok","timestamp":1738672051300,"user_tz":-120,"elapsed":498,"user":{"displayName":"Reza Shafiloo","userId":"13455316872907877314"}},"outputId":"e54289ea-db86-483a-925e-83283d84abb4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Endpoint URL: https://4076-34-125-214-192.ngrok-free.app/analyze/\n","INFO:     34.125.214.192:0 - \"POST /analyze/ HTTP/1.1\" 200 OK\n","Response: {'sentiment': 'positive', 'confidence': 0.95}\n"]}]},{"cell_type":"code","source":["!pip install groq\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer\n","import requests\n","import os\n","\n","##############################\n","# 1. Load the Fine-Tuned Model from Hugging Face\n","##############################\n","\n","# Replace with your actual repository name on Hugging Face Hub\n","model_repo = \"rza121/imdb-finetuned-model\"\n","\n","# Load the fine-tuned model and tokenizer\n","fine_tuned_model = AutoModelForSequenceClassification.from_pretrained(model_repo)\n","fine_tuned_tokenizer = AutoTokenizer.from_pretrained(model_repo)\n","\n","print(\"Fine-tuned model and tokenizer loaded from Hugging Face!\")\n","\n","##############################\n","# 2. Access the Llama 3 Model via Groq Cloud API using the provided snippet\n","##############################\n","\n","from groq import Groq\n","\n","# Create a Groq client using your API key from an environment variable.\n","client = Groq(api_key=\"###############\")\n","\n","# Request a chat completion from the Llama 3 model.\n","chat_completion = client.chat.completions.create(\n","    messages=[\n","        {\n","            \"role\": \"user\",\n","            \"content\": \"Say Hello world!\",\n","        }\n","    ],\n","    model=\"llama-3.3-70b-versatile\",\n",")\n","\n","# Print the Llama 3 model response.\n","print(\"Llama 3 response:\")\n","print(chat_completion.choices[0].message.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ovmv4u-o3jmG","executionInfo":{"status":"ok","timestamp":1738678818565,"user_tz":-120,"elapsed":26444,"user":{"displayName":"Reza Shafiloo","userId":"13455316872907877314"}},"outputId":"2bed635e-9dbe-441d-848c-94e37027b796"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: groq in /usr/local/lib/python3.11/dist-packages (0.17.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.6)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n","Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2024.12.14)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Fine-tuned model and tokenizer loaded from Hugging Face!\n","Llama 3 response:\n","Hello world!\n"]}]},{"cell_type":"code","source":["# Import required modules\n","import os\n","import torch\n","from fastapi import FastAPI, HTTPException\n","from pydantic import BaseModel\n","import nest_asyncio\n","import uvicorn\n","from pyngrok import ngrok\n","import threading\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","from groq import Groq\n","import re\n","\n","# Apply nest_asyncio to allow nested event loops (required for Colab)\n","nest_asyncio.apply()\n","\n","# Kill existing ngrok tunnels to avoid exceeding the limit\n","ngrok.kill()\n","\n","# Optionally kill any processes using port 8003\n","!fuser -k 8003/tcp\n","\n","# Set your ngrok authtoken (replace with your actual authtoken)\n","ngrok.set_auth_token(\"####################\")\n","\n","groq_client = Groq(api_key=\"####################\")\n","app = FastAPI()\n","\n","# Define the request body structure using Pydantic.\n","class AnalyzeRequest(BaseModel):\n","    text: str\n","    model: str\n","\n","# Define the response structure.\n","class AnalyzeResponse(BaseModel):\n","    sentiment: str\n","    confidence: float\n","\n","@app.post(\"/analyze/\", response_model=AnalyzeResponse)\n","async def analyze(request: AnalyzeRequest):\n","    if not request.text:\n","        raise HTTPException(status_code=400, detail=\"Input text cannot be empty.\")\n","\n","    # Option 1: Use the fine-tuned Hugging Face model (\"custom\")\n","    if request.model.lower() == \"custom\":\n","        # Tokenize input text with truncation, padding and a max length of 256\n","        inputs = fine_tuned_tokenizer(\n","            request.text,\n","            return_tensors=\"pt\",\n","            truncation=True,\n","            padding=\"max_length\",\n","            max_length=256,\n","        )\n","        with torch.no_grad():\n","            outputs = fine_tuned_model(**inputs)\n","        logits = outputs.logits\n","        # Compute probabilities and select the highest scoring class\n","        probs = torch.softmax(logits, dim=-1)\n","        confidence_tensor, pred_class_tensor = torch.max(probs, dim=1)\n","        confidence = confidence_tensor.item()\n","        pred_class = pred_class_tensor.item()\n","        # Assume label mapping: 1 -> positive, 0 -> negative.\n","        sentiment = \"positive\" if pred_class == 1 else \"negative\"\n","        return AnalyzeResponse(sentiment=sentiment, confidence=confidence)\n","\n","      # Option 2: Use the Groq Cloud API to access the Llama 3 model (\"llama\")\n","    elif request.model.lower() == \"llama\":\n","        chat_completion = groq_client.chat.completions.create(\n","            messages=[\n","                {\"role\": \"user\", \"content\": request.text},\n","            ],\n","            model=\"llama-3.3-70b-versatile\",\n","        )\n","        # Get the raw response content from Llama 3\n","        llama_response = chat_completion.choices[0].message.content\n","        print(\"Llama Response (raw):\", llama_response)  # Debug output\n","\n","        # Determine sentiment from the response\n","        if \"positive\" in llama_response.lower():\n","            sentiment = \"positive\"\n","        else:\n","            sentiment = \"negative\"\n","\n","        # Initialize confidence variable to avoid unbound errors\n","        confidence = None\n","\n","        # First, look for a pattern like \"confidence: 0.92\" (case insensitive)\n","        match = re.search(r\"score[:\\s]*([\\d]+\\.[\\d]+)\", llama_response, re.IGNORECASE)\n","        if match:\n","            try:\n","                confidence = float(match.group(1))\n","            except ValueError:\n","                confidence = 0.9\n","        else:\n","            # As a fallback, search for any floating point number in the response\n","            match = re.search(r\"(\\d+\\.\\d+)\", llama_response)\n","            if match:\n","                try:\n","                    confidence = float(match.group(1))\n","                except ValueError:\n","                    confidence = 0.9\n","            else:\n","                confidence = 0.9  # Default value if no number is found\n","\n","        return AnalyzeResponse(sentiment=sentiment, confidence=confidence)\n","\n","    else:\n","        raise HTTPException(status_code=400, detail=\"Invalid model specified. Choose 'custom' or 'llama'.\")\n","\n","##############################\n","# Start the API with Uvicorn and Expose via ngrok\n","##############################\n","\n","# Define the port number (using 8003)\n","port = 8003\n","\n","# Start an ngrok tunnel on the selected port\n","tunnel = ngrok.connect(port)\n","public_url = tunnel.public_url  # e.g., \"http://xxxx.ngrok.io\"\n","print(\"ngrok tunnel created! Public URL:\", public_url)\n","\n","# Function to run the Uvicorn server\n","def run():\n","    uvicorn.run(app, host=\"0.0.0.0\", port=port)\n","\n","# Start the server in a background thread.\n","thread = threading.Thread(target=run)\n","thread.start()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AiRb4rKm9JAu","executionInfo":{"status":"ok","timestamp":1738678823955,"user_tz":-120,"elapsed":1892,"user":{"displayName":"Reza Shafiloo","userId":"13455316872907877314"}},"outputId":"934305c5-4099-400e-bc53-5ac6220685e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ngrok tunnel created! Public URL: https://8515-34-125-214-192.ngrok-free.app\n"]},{"output_type":"stream","name":"stderr","text":["INFO:     Started server process [68250]\n","INFO:     Waiting for application startup.\n","INFO:     Application startup complete.\n","INFO:     Uvicorn running on http://0.0.0.0:8003 (Press CTRL+C to quit)\n"]}]},{"cell_type":"code","source":["import requests\n","import json\n","import os\n","\n","# ------------------------------------------------------------------------------\n","# Instructions for Testing with Postman:\n","# ------------------------------------------------------------------------------\n","# 1. Open Postman and create a new POST request.\n","# 2. Set the request URL to:\n","#       {public_url}/analyze/\n","#    (Replace {public_url} with the actual ngrok URL printed by your server.)\n","# 3. Set the header \"Content-Type\" to \"application/json\".\n","# 4. For testing the \"custom\" model, use this JSON in the body:\n","#       {\n","#           \"text\": \"This movie was really good!\",\n","#           \"model\": \"custom\"\n","#       }\n","#    For testing the \"llama\" model, use:\n","#       {\n","#           \"text\": \"Explain the importance of fast language models\",\n","#           \"model\": \"llama\"\n","#       }\n","# 5. Send the request and verify the response.\n","#\n","# ------------------------------------------------------------------------------\n","# Testing the /analyze/ endpoint using Python requests:\n","# ------------------------------------------------------------------------------\n","endpoint_url = public_url + \"/analyze/\"\n","print(\"Endpoint URL:\", endpoint_url)\n","\n","# Test with the \"custom\" model:\n","payload_custom = {\"text\": \"This movie was really good!\", \"model\": \"custom\"}\n","response_custom = requests.post(endpoint_url, json=payload_custom)\n","print(\"\\nPython requests response for custom model:\")\n","print(response_custom.json())\n","\n","# Test with the \"llama\" model:\n","payload_llama = {\"text\": \"This movie was really good!\", \"model\": \"llama\"}\n","response_llama = requests.post(endpoint_url, json=payload_llama)\n","print(\"\\nPython requests response for llama model:\")\n","print(response_llama.json())\n","\n","# ------------------------------------------------------------------------------\n","# Testing the /analyze/ endpoint using curl commands:\n","# ------------------------------------------------------------------------------\n","print(\"\\nTesting with curl (outputs below):\")\n","\n","# Note: In Google Colab, you can use shell commands with !. The variable endpoint_url\n","# is substituted by placing it in curly braces inside a string.\n","os.environ['ENDPOINT_URL'] = endpoint_url\n","\n","print(\"\\nTesting with curl (custom model):\")\n","!curl -X POST \"$ENDPOINT_URL\" -H \"Content-Type: application/json\" -d '{\"text\": \"This movie was really good!\", \"model\": \"custom\"}'\n","\n","print(\"\\nTesting with curl (llama model):\")\n","!curl -X POST \"$ENDPOINT_URL\" -H \"Content-Type: application/json\" -d '{\"text\": \"This movie was really good!\", \"model\": \"llama\"}'\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CA52Jg2VCUZz","executionInfo":{"status":"ok","timestamp":1738678830880,"user_tz":-120,"elapsed":5013,"user":{"displayName":"Reza Shafiloo","userId":"13455316872907877314"}},"outputId":"50ef25e1-eb21-4432-d410-032dced4ce6c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Endpoint URL: https://8515-34-125-214-192.ngrok-free.app/analyze/\n","INFO:     34.125.214.192:0 - \"POST /analyze/ HTTP/1.1\" 200 OK\n","\n","Python requests response for custom model:\n","{'sentiment': 'positive', 'confidence': 0.9951962828636169}\n","Llama Response (raw): I'm glad you enjoyed the movie. What was it about that you liked? Was it the storyline, the characters, the acting, or something else? Would you like to discuss it or get recommendations for similar movies?\n","INFO:     34.125.214.192:0 - \"POST /analyze/ HTTP/1.1\" 200 OK\n","\n","Python requests response for llama model:\n","{'sentiment': 'negative', 'confidence': 0.9}\n","\n","Testing with curl (outputs below):\n","\n","Testing with curl (custom model):\n","INFO:     34.125.214.192:0 - \"POST /analyze/ HTTP/1.1\" 200 OK\n","{\"sentiment\":\"positive\",\"confidence\":0.9951962828636169}\n","Testing with curl (llama model):\n","Llama Response (raw): That's great to hear! I'd love to know more about the movie you enjoyed. Can you tell me which one it was and what you liked about it? Was it a recent release or a classic film?\n","INFO:     34.125.214.192:0 - \"POST /analyze/ HTTP/1.1\" 200 OK\n","{\"sentiment\":\"negative\",\"confidence\":0.9}"]}]},{"cell_type":"code","source":["import requests\n","import json\n","import os\n","\n","# ------------------------------------------------------------------------------\n","# Instructions for Testing with Postman:\n","# ------------------------------------------------------------------------------\n","# 1. Open Postman and create a new POST request.\n","# 2. Set the request URL to:\n","#       {public_url}/analyze/\n","#    (Replace {public_url} with the actual ngrok URL printed by your server.)\n","# 3. Set the header \"Content-Type\" to \"application/json\".\n","# 4. For testing the \"custom\" model, use this JSON in the body:\n","#       {\n","#           \"text\": \"This movie was really good!\",\n","#           \"model\": \"custom\"\n","#       }\n","#    For testing the \"llama\" model, use:\n","#       {\n","#           \"text\": \"Explain the importance of fast language models\",\n","#           \"model\": \"llama\"\n","#       }\n","# 5. Send the request and verify the response.\n","#\n","# ------------------------------------------------------------------------------\n","# Testing the /analyze/ endpoint using Python requests:\n","# ------------------------------------------------------------------------------\n","endpoint_url = public_url + \"/analyze/\"\n","print(\"Endpoint URL:\", endpoint_url)\n","\n","# Test with the \"custom\" model:\n","payload_custom = {\"text\": \"This movie was really good!\", \"model\": \"custom\"}\n","response_custom = requests.post(endpoint_url, json=payload_custom)\n","print(\"\\nPython requests response for custom model:\")\n","print(response_custom.json())\n","\n","# Test with the \"llama\" model:\n","payload_llama = {\"text\": \"Classify the sentiment of this text as positive or negative: \"+\"This movie was really good!\", \"model\": \"llama\"}\n","response_llama = requests.post(endpoint_url, json=payload_llama)\n","print(\"\\nPython requests response for llama model:\")\n","print(response_llama.json())\n","\n","# ------------------------------------------------------------------------------\n","# Testing the /analyze/ endpoint using curl commands:\n","# ------------------------------------------------------------------------------\n","print(\"\\nTesting with curl (outputs below):\")\n","\n","# Note: In Google Colab, you can use shell commands with !. The variable endpoint_url\n","# is substituted by placing it in curly braces inside a string.\n","\n","os.environ['ENDPOINT_URL'] = endpoint_url\n","\n","print(\"\\nTesting with curl (custom model):\")\n","!curl -X POST \"$ENDPOINT_URL\" -H \"Content-Type: application/json\" -d '{\"text\": \"This movie was really good!\", \"model\": \"custom\"}'\n","\n","print(\"\\nTesting with curl (llama model):\")\n","!curl -X POST \"$ENDPOINT_URL\" -H \"Content-Type: application/json\" -d '{\"text\": \"Classify the sentiment of this text as positive or negative: This movie was really good!\", \"model\": \"llama\"}'\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3f7mz2A9LMqF","executionInfo":{"status":"ok","timestamp":1738678846733,"user_tz":-120,"elapsed":4056,"user":{"displayName":"Reza Shafiloo","userId":"13455316872907877314"}},"outputId":"8e0f8fab-27a2-4d06-8e92-9e7964977e64"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Endpoint URL: https://8515-34-125-214-192.ngrok-free.app/analyze/\n","INFO:     34.125.214.192:0 - \"POST /analyze/ HTTP/1.1\" 200 OK\n","\n","Python requests response for custom model:\n","{'sentiment': 'positive', 'confidence': 0.9951962828636169}\n","Llama Response (raw): The sentiment of this text is positive. The phrase \"really good\" indicates a favorable opinion of the movie.\n","INFO:     34.125.214.192:0 - \"POST /analyze/ HTTP/1.1\" 200 OK\n","\n","Python requests response for llama model:\n","{'sentiment': 'positive', 'confidence': 0.9}\n","\n","Testing with curl (outputs below):\n","\n","Testing with curl (custom model):\n","INFO:     34.125.214.192:0 - \"POST /analyze/ HTTP/1.1\" 200 OK\n","{\"sentiment\":\"positive\",\"confidence\":0.9951962828636169}\n","Testing with curl (llama model):\n","Llama Response (raw): The sentiment of this text is positive. The word \"good\" has a positive connotation, and the emphasis added by \"really\" strengthens the positive sentiment. Overall, the text expresses a favorable opinion of the movie.\n","INFO:     34.125.214.192:0 - \"POST /analyze/ HTTP/1.1\" 200 OK\n","{\"sentiment\":\"positive\",\"confidence\":0.9}"]}]},{"cell_type":"code","source":["\n","os.environ['ENDPOINT_URL'] = endpoint_url\n","\n","print(\"\\nTesting with curl (custom model):\")\n","!curl -X POST \"$ENDPOINT_URL\" -H \"Content-Type: application/json\" -d '{\"text\": \"This movie was really good!\", \"model\": \"custom\"}'\n","\n","print(\"\\nTesting with curl (llama model):\")\n","!curl -X POST \"$ENDPOINT_URL\" -H \"Content-Type: application/json\" -d '{\"text\": \"Classify the sentiment of this text as positive or negative: This movie was really good! and give sentiment score from 0 to 1 to this sentece\", \"model\": \"llama\"}'\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QrDv7mXCP863","executionInfo":{"status":"ok","timestamp":1738678937520,"user_tz":-120,"elapsed":2546,"user":{"displayName":"Reza Shafiloo","userId":"13455316872907877314"}},"outputId":"f3f86058-3c26-4182-d296-b9e04aedf8a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Testing with curl (custom model):\n","INFO:     34.125.214.192:0 - \"POST /analyze/ HTTP/1.1\" 200 OK\n","{\"sentiment\":\"positive\",\"confidence\":0.9951962828636169}\n","Testing with curl (llama model):\n","Llama Response (raw): I would classify the sentiment of the text as: **Positive**\n","\n","The phrase \"really good\" is a strong positive expression, indicating that the speaker enjoyed the movie.\n","\n","Sentiment score: **0.9** (out of 1)\n","\n","The score is close to 1, indicating a very positive sentiment, as the speaker uses a strong positive adjective (\"really good\") to express their opinion about the movie.\n","INFO:     34.125.214.192:0 - \"POST /analyze/ HTTP/1.1\" 200 OK\n","{\"sentiment\":\"positive\",\"confidence\":0.9}"]}]},{"cell_type":"code","source":["# Install ipywidgets if not already installed (uncomment the next line if needed)\n","!pip install ipywidgets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GsCmX_hnfloq","executionInfo":{"status":"ok","timestamp":1738681514189,"user_tz":-120,"elapsed":5259,"user":{"displayName":"Reza Shafiloo","userId":"13455316872907877314"}},"outputId":"86cb1e5f-f4fb-4e43-efc6-d6b8d0cc959d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (7.7.1)\n","Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (5.5.6)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (0.2.0)\n","Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (5.7.1)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.6.10)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (7.34.0)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.0.13)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n","Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.4.2)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (75.1.0)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.19.2)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.50)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (2.18.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.5)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.5)\n","Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.0.1)\n","Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1.0)\n","Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.7.2)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n","Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.16.6)\n","Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.6.0)\n","Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n","Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.21.1)\n","Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.2.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.13)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.3.6)\n","Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.12.3)\n","Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.2.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n","Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.2)\n","Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.1)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.2)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21.1)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.23.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.1->jupyter-client->ipykernel>=4.5.1->ipywidgets) (1.17.0)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n","Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.1.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2024.10.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.22.3)\n","Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.24.0)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.17.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.6)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.22)\n","Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.7.1)\n","Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n","Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.12.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.10)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n"]}]},{"cell_type":"code","source":["import ipywidgets as widgets\n","from IPython.display import display\n","import requests\n","\n","# Create a text input widget\n","text_input = widgets.Text(\n","    value='',\n","    placeholder='Type your sentence here...',\n","    description='Input:',\n","    style={'description_width': 'initial'},\n","    layout=widgets.Layout(width='400px')\n",")\n","\n","# Create a dropdown widget for model selection\n","model_dropdown = widgets.Dropdown(\n","    options=[('Custom Model', 'custom'), ('Llama 3', 'llama')],\n","    value='custom',\n","    description='Model:',\n","    style={'description_width': 'initial'}\n",")\n","\n","# Create a button widget to trigger sentiment analysis\n","analyze_button = widgets.Button(\n","    description='Analyze Sentiment',\n","    button_style='primary',  # 'success', 'info', 'warning', 'danger' or ''\n","    tooltip='Click to analyze sentiment',\n","    icon='check'\n",")\n","\n","# Create an output widget to display results\n","output = widgets.Output()\n","\n","# Define the function to call when the button is clicked\n","def analyze_sentiment(b):\n","    output.clear_output()  # Clear previous output\n","    text = text_input.value\n","    model = model_dropdown.value\n","\n","    if not text:\n","        with output:\n","            print(\"Please enter some text.\")\n","        return\n","\n","    # Build the API endpoint URL (replace with your actual endpoint)\n","    endpoint_url = public_url + \"/analyze/\"\n","    payload = {\"text\": text, \"model\": model}\n","\n","    # For the Llama model, modify the prompt as required.\n","    if model == \"llama\":\n","        payload[\"text\"] = (\"Classify the sentiment of this text as positive or negative and give final sentiment score [0,1] for this: \"\n","                           + text)\n","\n","    try:\n","        response = requests.post(endpoint_url, json=payload)\n","        # Try to parse the JSON response\n","        result = response.json()\n","    except Exception as e:\n","        result = {\"error\": str(e)}\n","\n","    with output:\n","        print(\"Result:\")\n","        print(result)\n","\n","# Attach the function to the button click event\n","analyze_button.on_click(analyze_sentiment)\n","\n","# Display the UI components\n","display(text_input, model_dropdown, analyze_button, output)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":287,"referenced_widgets":["9303e2c18ade4880ba2a381e4a38179d","03388ba7165d40c597440990d8f6914f","36c739d6c7574e3aa8889867e128149b","449698dbe77e4a4aa0d7c9c47d793f9c","e2817fcabc80416c929ce09123dfb0d3","9e46e3f9c29a4ac7aaf67867284ae102","96e66106ea774db9b7d577290e2cabb8","f419b7533a834becad85ed4098f3500d","c9294b45199f4872974a4650dc5a9a7f","1d24f3c5dc824619b1bedc93d3d59bc8","cb63a7944438447a80c647643fe90756"]},"id":"vGLj5enyVmWy","executionInfo":{"status":"ok","timestamp":1738681517020,"user_tz":-120,"elapsed":294,"user":{"displayName":"Reza Shafiloo","userId":"13455316872907877314"}},"outputId":"82fb39e5-3121-4216-b3d4-a4e33a673011"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Text(value='', description='Input:', layout=Layout(width='400px'), placeholder='Type your sentence here...', s…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9303e2c18ade4880ba2a381e4a38179d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Dropdown(description='Model:', options=(('Custom Model', 'custom'), ('Llama 3', 'llama')), style=DescriptionSt…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"449698dbe77e4a4aa0d7c9c47d793f9c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Button(button_style='primary', description='Analyze Sentiment', icon='check', style=ButtonStyle(), tooltip='Cl…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96e66106ea774db9b7d577290e2cabb8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Output()"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d24f3c5dc824619b1bedc93d3d59bc8"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["INFO:     34.125.214.192:0 - \"POST /analyze/ HTTP/1.1\" 200 OK\n","Llama Response (raw): The sentiment of this text is: Positive\n","\n","The final sentiment score is: 0.9\n","\n","The text contains the phrase \"really good\", which is a strong positive expression, indicating a high level of satisfaction or approval. The score of 0.9 reflects this, with 1 being the most positive sentiment possible.\n","INFO:     34.125.214.192:0 - \"POST /analyze/ HTTP/1.1\" 200 OK\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Re30YHZwYMgV"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"13j4c9AvE1LKKXVb0DwP5HV8EGa3E5FL1","timestamp":1738661221629}],"authorship_tag":"ABX9TyM8bwIFDrrs6xNaRlR2rJWn"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a2b75a5ea86d499ea1f01d677df5e0d5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cbe9d213797542ebac54b9d27fb6032d","IPY_MODEL_cdde8509e17d4f808dd6c4349641dcf9","IPY_MODEL_4d4674fb51904c1983e508d8bca6df5c"],"layout":"IPY_MODEL_e3e3929047034234b35aa11052b44798"}},"cbe9d213797542ebac54b9d27fb6032d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_394d58d2d7de463c8b155e85b8be16b6","placeholder":"​","style":"IPY_MODEL_e08dbc39a361471e9e3ba789c7ca7fc5","value":"model.safetensors: 100%"}},"cdde8509e17d4f808dd6c4349641dcf9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf8d2cb4b8764084912cca9f1afa06fd","max":267954768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dcdd3b9eaf8b4de2ac672806cffbfbd6","value":267954768}},"4d4674fb51904c1983e508d8bca6df5c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1cac4692477e4d88b8cab17ef1f7d950","placeholder":"​","style":"IPY_MODEL_b2f067a0a3674fbaa19b6b4f5d5fd0cf","value":" 268M/268M [00:01&lt;00:00, 230MB/s]"}},"e3e3929047034234b35aa11052b44798":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"394d58d2d7de463c8b155e85b8be16b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e08dbc39a361471e9e3ba789c7ca7fc5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf8d2cb4b8764084912cca9f1afa06fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dcdd3b9eaf8b4de2ac672806cffbfbd6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1cac4692477e4d88b8cab17ef1f7d950":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2f067a0a3674fbaa19b6b4f5d5fd0cf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec31ab034b6341f09f90e2d0b6b5ffa1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f8dddccdf18446f78d2192dcd27c0bdf","IPY_MODEL_3c9e966b05324c28995fc4dd031c0fb5","IPY_MODEL_78cb9eac7ab04e7dafe945c9408edf6d"],"layout":"IPY_MODEL_6f847ffb05cb4173abe5f6a4eae5abe3"}},"f8dddccdf18446f78d2192dcd27c0bdf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_41d0b4373d984579a3f684ae5c874d5a","placeholder":"​","style":"IPY_MODEL_2551d6af41514cadaf046608b47880c4","value":"model.safetensors: 100%"}},"3c9e966b05324c28995fc4dd031c0fb5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9dc1e43ddc14b71a9e78cec3c1a63f0","max":267832560,"min":0,"orientation":"horizontal","style":"IPY_MODEL_55527ec61dfd42c9b014920efde60796","value":267832560}},"78cb9eac7ab04e7dafe945c9408edf6d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c31aaa1b7107409e8e83b7963a30515c","placeholder":"​","style":"IPY_MODEL_30c2793f21684e2d9121e1607f8d5401","value":" 268M/268M [00:09&lt;00:00, 40.5MB/s]"}},"6f847ffb05cb4173abe5f6a4eae5abe3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41d0b4373d984579a3f684ae5c874d5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2551d6af41514cadaf046608b47880c4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9dc1e43ddc14b71a9e78cec3c1a63f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55527ec61dfd42c9b014920efde60796":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c31aaa1b7107409e8e83b7963a30515c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30c2793f21684e2d9121e1607f8d5401":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9303e2c18ade4880ba2a381e4a38179d":{"model_module":"@jupyter-widgets/controls","model_name":"TextModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"TextModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"TextView","continuous_update":true,"description":"Input:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_03388ba7165d40c597440990d8f6914f","placeholder":"Type your sentence here...","style":"IPY_MODEL_36c739d6c7574e3aa8889867e128149b","value":"This movie was really good!"}},"03388ba7165d40c597440990d8f6914f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"400px"}},"36c739d6c7574e3aa8889867e128149b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":"initial"}},"449698dbe77e4a4aa0d7c9c47d793f9c":{"model_module":"@jupyter-widgets/controls","model_name":"DropdownModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DropdownModel","_options_labels":["Custom Model","Llama 3"],"_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"DropdownView","description":"Model:","description_tooltip":null,"disabled":false,"index":1,"layout":"IPY_MODEL_e2817fcabc80416c929ce09123dfb0d3","style":"IPY_MODEL_9e46e3f9c29a4ac7aaf67867284ae102"}},"e2817fcabc80416c929ce09123dfb0d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e46e3f9c29a4ac7aaf67867284ae102":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":"initial"}},"96e66106ea774db9b7d577290e2cabb8":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"primary","description":"Analyze Sentiment","disabled":false,"icon":"check","layout":"IPY_MODEL_f419b7533a834becad85ed4098f3500d","style":"IPY_MODEL_c9294b45199f4872974a4650dc5a9a7f","tooltip":"Click to analyze sentiment"}},"f419b7533a834becad85ed4098f3500d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9294b45199f4872974a4650dc5a9a7f":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"1d24f3c5dc824619b1bedc93d3d59bc8":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_cb63a7944438447a80c647643fe90756","msg_id":"","outputs":[{"output_type":"stream","name":"stdout","text":["Result:\n","{'sentiment': 'positive', 'confidence': 0.9}\n"]}]}},"cb63a7944438447a80c647643fe90756":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}